{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59049 pairs of rankings\n",
      "\n",
      "P:  ('N', 'HR', 'HR', 'HR', 'N') \n",
      "E:  ('R', 'R', 'R', 'HR', 'HR') \n",
      "\n",
      "['N', 'N', 'R', 'R', 'R', 'HR', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('HR', 'R', 'N', 'N', 'N') \n",
      "E:  ('N', 'N', 'HR', 'N', 'HR') \n",
      "\n",
      "['N', 'N', 'N', 'N', 'N', 'N', 'R', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('HR', 'R', 'R', 'HR', 'HR') \n",
      "E:  ('N', 'N', 'R', 'HR', 'R') \n",
      "\n",
      "['N', 'N', 'R', 'R', 'R', 'R', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('N', 'N', 'N', 'HR', 'R') \n",
      "E:  ('HR', 'R', 'HR', 'R', 'HR') \n",
      "\n",
      "['N', 'N', 'N', 'R', 'R', 'R', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('HR', 'N', 'R', 'R', 'R') \n",
      "E:  ('HR', 'HR', 'HR', 'R', 'N') \n",
      "\n",
      "['N', 'N', 'R', 'R', 'R', 'R', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('R', 'R', 'HR', 'N', 'R') \n",
      "E:  ('R', 'N', 'N', 'N', 'R') \n",
      "\n",
      "['N', 'N', 'N', 'N', 'R', 'R', 'R', 'R', 'R', 'HR']\n",
      "\n",
      "P:  ('N', 'HR', 'R', 'HR', 'HR') \n",
      "E:  ('HR', 'N', 'HR', 'N', 'R') \n",
      "\n",
      "['N', 'N', 'N', 'R', 'R', 'HR', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('HR', 'R', 'HR', 'R', 'N') \n",
      "E:  ('R', 'N', 'HR', 'HR', 'R') \n",
      "\n",
      "['N', 'N', 'R', 'R', 'R', 'R', 'HR', 'HR', 'HR', 'HR']\n",
      "\n",
      "P:  ('N', 'HR', 'R', 'N', 'N') \n",
      "E:  ('R', 'HR', 'R', 'R', 'R') \n",
      "\n",
      "['N', 'N', 'N', 'R', 'R', 'R', 'R', 'R', 'HR', 'HR']\n",
      "\n",
      "P:  ('N', 'N', 'N', 'N', 'N') \n",
      "E:  ('R', 'HR', 'N', 'R', 'N') \n",
      "\n",
      "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'R', 'R', 'HR']\n",
      "\n",
      "P:  ('N', 'HR', 'HR', 'N', 'R') \n",
      "E:  ('HR', 'R', 'R', 'R', 'N') \n",
      "\n",
      "['N', 'N', 'N', 'R', 'R', 'R', 'R', 'HR', 'HR', 'HR']\n",
      "MAP (P) after 11 results: 0.34545454545454546\n",
      "MAP (E) after 11 results: 0.48758116883116887\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "relevances = { 'N':0, 'R':1, 'HR':2 }\n",
    "rankingsOf5 = list(itertools.product(list(relevances.keys()), repeat=5))\n",
    "pairsOfRankingsOf5 = list(itertools.product(rankingsOf5, rankingsOf5))\n",
    "shuffle(pairsOfRankingsOf5)\n",
    "print(len(pairsOfRankingsOf5), \"pairs of rankings\")\n",
    "\n",
    "def getContingencies (items, k, relevantDocumentCount):\n",
    "    retrievedCounter = Counter(items[:k])\n",
    "    TP = retrievedCounter['R'] + retrievedCounter['HR']\n",
    "    FP = retrievedCounter['N']\n",
    "    \n",
    "    notRetrievedCounter = Counter(items[k:])\n",
    "    TN = notRetrievedCounter['N']\n",
    "    FN = relevantDocumentCount - TP\n",
    "    \n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def getPrecisionAtK (ranking, k):\n",
    "    TP, FP, TN, FN = getContingencies(ranking, k, relevantDocumentCount)\n",
    "    precisionAtK = TP / (TP + FP)\n",
    "#     recallAtK = TP / (TP + FN)\n",
    "#     F1AtK = 2*precisionAtK*recallAtK\n",
    "#     if F1AtK > 0.0: \n",
    "#         F1AtK /= precisionAtK + recallAtK\n",
    "#     accuracyAtK = (TP + TN)/(TP + FP + FN + TN)\n",
    "    return precisionAtK\n",
    "\n",
    "def getAveragePrecision (ranking, relevantDocumentCount):\n",
    "    precisionsForAp = []\n",
    "    for k in range(1, len(ranking)+1):\n",
    "        precisionAtK = getPrecisionAtK(ranking, k)\n",
    "\n",
    "        if ranking[k-1] == 'R' or ranking[k-1] == 'HR':\n",
    "            # save for calculating AP later\n",
    "            precisionsForAp.append(precisionAtK)\n",
    "    \n",
    "    averagePrecision = sum(precisionsForAp)/relevantDocumentCount\n",
    "    return averagePrecision\n",
    "\n",
    "def getDiscountedCumulativeGain (ranking):\n",
    "    dcg = 0.0\n",
    "    for r in range(1, len(ranking)+1):\n",
    "        relevanceAtR = 0\n",
    "        if ranking[r-1] == 'R':\n",
    "            relevanceAtR = 1\n",
    "        elif ranking[r-1] == 'HR':\n",
    "            relevanceAtR = 2\n",
    "        gain = (2 ** relevanceAtR) - 1\n",
    "        discount = math.log2(1 + r)\n",
    "        dcg += gain/discount\n",
    "    return dcg\n",
    "\n",
    "\n",
    "averagePrecisionsForMapP = []\n",
    "averagePrecisionsForMapE = []\n",
    "\n",
    "for i, rankingPair in enumerate(pairsOfRankingsOf5):\n",
    "    P = rankingPair[0]\n",
    "    E = rankingPair[1]\n",
    "    \n",
    "    # show the pair\n",
    "    print ('\\nP: ', P, '\\nE: ', E, '\\n')\n",
    "\n",
    "    # implement 1 of (binary):\n",
    "    #   precision at rank k\n",
    "    #   recall at rank k\n",
    "    #   average precision   <--\n",
    "    totalCounter = Counter(P) + Counter(E)\n",
    "    relevantDocumentCount = totalCounter['R'] + totalCounter['HR']\n",
    "    \n",
    "    if relevantDocumentCount == 0:\n",
    "        # result is irrelevant\n",
    "        continue\n",
    "        \n",
    "    averagePrecisionP = getAveragePrecision(P, relevantDocumentCount)\n",
    "    averagePrecisionE = getAveragePrecision(E, relevantDocumentCount)\n",
    "    \n",
    "    # save for calculating MAP later\n",
    "    averagePrecisionsForMapP.append(averagePrecisionP)\n",
    "    averagePrecisionsForMapE.append(averagePrecisionE)\n",
    "\n",
    "    # implement 2 of (multi-graded):\n",
    "    #   nDCG at rank k\n",
    "    #   ERR\n",
    "    \n",
    "    # Normalized Discounted Cumulative Gain\n",
    "    # first we have to determine the perfect ranking. Assuming the P and E results are always\n",
    "    # different, the perfect ranking would include the results from both lists.\n",
    "    k = 3\n",
    "    mergedRanking = P + E\n",
    "    perfectRanking = sorted(mergedRanking, key=lambda relevance: relevances[relevance])\n",
    "    print(perfectRanking)\n",
    "    perfectDcgScoreP = getDiscountedCumulativeGain(mergedRanking[:k])\n",
    "    \n",
    "    # only try a few for now\n",
    "    if i >= 10:\n",
    "        break;\n",
    "        \n",
    "        \n",
    "        \n",
    "meanAveragePrecisionP = sum(averagePrecisionsForMapP)/len(averagePrecisionsForMapP)\n",
    "meanAveragePrecisionE = sum(averagePrecisionsForMapE)/len(averagePrecisionsForMapE)\n",
    "print('MAP (P) after {} results: {}'.format(len(averagePrecisionsForMapP), meanAveragePrecisionP))\n",
    "print('MAP (E) after {} results: {}'.format(len(averagePrecisionsForMapE), meanAveragePrecisionE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
